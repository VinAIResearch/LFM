<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Latent Flow Matching">
  <meta name="keywords" content="LFM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Flow matching in Latent Space</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook('TeX Jax Ready', function () {
          MathJax.InputJax.TeX.prefilterHooks.Add(function (data) {
            data.math = data.math.replace('<br/>', '\\');
          });
        });
  </script>
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

</head>

<body>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Flow Matching in Latent Space</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://quandao10.github.io/">Quan Dao*</a><sup>1</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://hao-pt.github.io/">Hao Phung*</a><sup>1</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://tbng.github.io/">Binh Nguyen</a><sup>2</sup>&emsp;
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/anhttranusc/">Anh Tran</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>VinAI Research</span> &emsp;
              <span class="author-block"><sup>2</sup>National University of Singapore</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <emp><sup>*</sup>Equal contribution</emp>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2307.08698" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/VinAIResearch/LFM"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="./static/images/archi.svg" class="framework" />
        <!-- has-text-centered -->
        <h3 class="subtitle has-text-centered">
          <div class="content has-text-justified">
            <p>
              Input data is first encoded to produce the latent vector \( z_0 \) which is used to trained an velocity
              estimator
              of the transformation from a standard normal distribution \( p(z_1) = \mathcal{N}(0, \mathbf{I}) \) to the
              target latent distribution \( p(z_0) \).
            </p>
            <p>
              Sampling process starts from random noise \( z_1 \), the trained network is used to predict the
              velocity towards the target latent distribution
              \( p(z_0) \) through numerical integration. Finally, \( z_0 \) is decoded to generate the corresponding
              image.
            </p>

          </div>
        </h3>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-starfish">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls327_cfg4.0.jpeg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Starfish' (327)
              </div>
            </div>
          </div>
          <div class="item item-macaw">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls88_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Macaw' (88)
              </div>
            </div>
          </div>
          <div class="item item-golden-retriever">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls207_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Golden retriever' (207)
              </div>
            </div>
          </div>
          <div class="item item-boathouse">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls449_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Boathouse' (449)
              </div>
            </div>
          </div>
          <div class="item item-mushroom">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls947_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Mushroom' (947)
              </div>
            </div>
          </div>
          <div class="item item-cliff">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls972_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Cliff' (972)
              </div>
            </div>
          </div>
          <div class="item item-coral-reef">
            <img src="static/images/samples_imagenet_256_dopri5_1e-05_1e-05_cls973_cfg4.0.jpg"
              class="interpolation-image" />
            <div class="card-content slider-text" style="background-color: rgba(0,0,0,0.1)">
              <div class="is-size-5 has-text-centered">
                Class: 'Coral reef' (973)
              </div>
            </div>
          </div>
        </div>
      </div><br>
      <div class="content has-text-centered">
        Class-conditional image generation on ImageNet
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models. Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space. Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area. In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis. This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility. Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation. Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church & Bedroom, and ImageNet. We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Unconditional Generation</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section" id="motivation">
    <div class="container is-max-desktop content">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <!-- Motivation -->
          <h2 class="title is-3">Motivation</h2>
          <div class="content has-text-justified">
            <p>
              Flow Matching (FM) has revolutionized the training of continuous normalizing flows (CNF) by introducing
              a
              simulation-free approach. Recent works, based on optimal transport theory, simplifies the training
              objective by assuming a constant velocity field
              between data and noise. This simplification results in straighter probability paths compared to the
              high-curvature paths in diffusion models, making FM an efficient approach for
              training continuous normalizing flows (CNF).
            </p>
            <p>
              However, FM is still in its early stages and not yet ready for high-resolution image synthesis due to
              its
              costly ODE sampling process. Our approach represents a pioneering effort to thoroughly integrate and
              study latent representations for flow-matching models, with the aim of enhancing both scalability and
              performance.
            </p>
            <p>
              Besides, the application of flow-based models in class-conditional
              generation remain unexplored. Hence, we introduce classifier-free velocity field, inspired by the concept
              of classifier-free guidance in diffusion models. Despite employing the same technique, our approach
              distinguishes itself by relying on a velocity field instead of noise, leading to a distinctive
              method for class-conditional generation. Additionally, our method supports different types of conditions,
              enabling tasks such as image inpainting and mask-to-image generation.
            </p>

          </div>

          <h3 class="title is-4">Why opt for the latent space?</h3>
          <div class="content has-text-justified">
            <p>
              <strong>Efficient computing:</strong> The most compelling advantage of the latent space is its compact
              representation,
              which enables smaller
              spatial dimensions. This property greatly benefits high-resolution synthesis by reducing the
              computational cost associated with evaluating numerical solvers at each step.
            </p>
            <p>
              <strong>Expressivity:</strong> As found in prior latent-based diffusion models, training a generative
              model on latent
              variables typically lead to the improvement in expressivity, thereby enhancing model performance. Based
              upon these findings, we expect that our model, through the combination of FM and a
              carefully selected latent framework, will exhibit heightened expressivity.
            </p>
            <p>
              As a result, the latent
              space empowers efficient training and sampling while enabling the generation of high-quality outputs.
            </p>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <!-- <div class="column">
          <div class="content">
            <h2 class="title is-3">Image Inpainting</h2>
            <p>
              Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
              would be impossible without nerfies since it would require going through a wall.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/dollyzoom-stacked.mp4" type="video/mp4">
            </video>
          </div>
        </div> -->
        <!-- / Visual Effects. -->

        <!-- Matting. -->
        <!-- <div class="column">
          <h2 class="title is-3">Semantic Synthesis</h2>
          <div class="columns is-centered">
            <div class="column content">
              <p>
                As a byproduct of our method, we can also solve the matting problem by ignoring
                samples that fall outside of a bounding box during rendering.
              </p>
              <video id="matting-video" controls playsinline height="100%">
                <source src="./static/videos/matting.mp4" type="video/mp4">
              </video>
            </div>

          </div>
        </div> -->
        <!-- </div> -->
        <!--/ Matting. -->

        <!-- Method. -->
        <div class="column is-full-width">
          <h2 class="title is-3">Method</h2>

          <!-- Interpolating. -->
          <h3 class="title is-4">Unconditional model</h3>
          <div class="content has-text-justified">
            <p>
              The training and sampling procedure of unconditional model are described as follow.
            </p>
            <div class="content has-text-centered">
              <figure>
                <img src="./static/images/uncond_algorithms.jpeg" class="interpolation-image" />
                <!-- <figcaption>Fig 1. Pseudocode of unconditional model</figcaption> -->
              </figure>
            </div>
          </div>
          <!-- <div class="columns is-vcentered interpolation-panel">
            <div class="column interpolation-video-column">
              <div id="interpolation-image-wrapper">
                Loading...
              </div>
              <input class="slider is-fullwidth is-large is-info" id="interpolation-slider" step="1" min="0" max="100"
                value="0" type="range">
            </div>
            <div class="column is-3 has-text-centered">
              <img src="./static/images/interpolate_end.jpg" class="interpolation-image-wrapper"
                alt="Interpolation end reference image." />
              <p class="is-bold">End Frame</p>
            </div>
          </div> -->
          <!-- <br /> -->
          <!--/ Interpolating. -->

          <!-- Re-rendering. -->
          <h3 class="title is-4">Class-conditional model</h3>
          <div class="content has-text-justified">
            <p>
              Unlike unconditional model, class-conditional model requires an extra class label in the training
              procedure. During training, we also incorporate the training of unconditional model with probability
              \( p_{u} \) (e.g. 0.1) to preserve generation diversity while aleviating the overfitting problem.

            </p>
          </div>
          <div class="content has-text-centered">
            <figure>
              <img src="./static/images/cond_algorithms.jpg" class="interpolation-image" />
              <!-- <figcaption>Fig 2. Pseudocode of conditional model</figcaption> -->
            </figure>
            <!-- <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="./static/videos/replay.mp4" type="video/mp4">
            </video> -->
          </div>
          <!--/ Re-rendering. -->

        </div>
        <!--/ Method. -->

      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full-width">
        <h2 class="title is-3">Downstream tasks</h2>
      </div>
      <div class="columns is-centered">
        <!-- Inpainting. -->
        <div class="column">
          <div class="content">
            <figure>
              <img src="./static/images/inpainting.png" class="interpolation-image" />
              <figcaption>Inpainting</figcaption>
            </figure>
          </div>
        </div>
        <!-- / Inpainting. -->

        <!-- Matting. -->
        <div class="column">
          <div class="content">
            <figure>
              <img src="./static/images/mask-image.png" class="interpolation-image" />
              <figcaption>Mask-to-image</figcaption>
            </figure>
          </div>
        </div>
      </div><br>
      <div class="content has-text-centered">
        The first row is the input images, the second row is our generated images and the last row is the reference
        images.
      </div>
    </div>
    </div>
  </section>

  <section class="section" id="bound">
    <div class="container is-max-desktop content">
      <h2 class="title">Theoretical analysis: Bounding estimation error</h2>
      <div class="content has-text-justified">
        We have shown that minimizing the FM objective on latent space controls the Wasserstein distance between the
        target density \( p_0 \) and the reconstructed density \( \hat{p}_0 \), which coincides with Fréchet inception
        distance (FID), a common metric for image generation.
        This means that our latent flow matching is guaranteed to control this metric, given reasonable estimation of \(
        \hat{v}(\mathbf{z}_t, t) \). Nonetheless, the analysis also suggests that the quality of latent flow matching
        depends on the constants that define the expressivity of the decoders and encoders, which has been observed in
        prior research on generative modeling in latent space.

        <img src="./static/images/bound.jpeg" class="interpolation-image" />


      </div>
    </div>
  </section>

  <section class="section" id="Related">
    <div class="container is-max-desktop content">
      <h2 class="title">Related Works</h2>
      <div class="content has-text-justified">
        <ul>

          <li>Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, Matthew Le. <a
              href="https://arxiv.org/abs/2210.02747"> Flow Matching for Generative Modeling</a>, ICLR 2023
            (Notable top 25%).</li><br>

          <li>Xingchao Liu, Chengyue Gong, Qiang Liu. <a href="https://arxiv.org/abs/2209.03003"> Flow Straight
              and
              Fast: Learning to Generate and Transfer Data with Rectified Flow</a>, ICLR 2023
            (Notable top 25%).</li><br>

          <li>Arash Vahdat, Karsten Kreis, Jan Kautz. <a href="https://arxiv.org/abs/2106.05931"> Score-based Generative
              Modeling in Latent Space</a>, NeurIPS 2021.</li><br>

          <li>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer. <a
              href="https://arxiv.org/abs/2106.05931"> High-Resolution Image
              Synthesis with Latent Diffusion Models</a>, CVPR 2022.</li><br>


          <li>Jonathan Ho, Tim Salimans. <a href="https://arxiv.org/abs/2207.12598"> Classifier-Free Diffusion
              Guidance</a>, NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications.</li><br>

          <li>Prafulla Dhariwal, Prafulla_Dhariwal1, Alexander Quinn Nichol. <a href="https://arxiv.org/abs/2105.05233">
              Diffusion Models Beat GANs on Image Synthesis</a>, NeurIPS
            2021 (Spotlight).</li><br>

          <li>William Peebles, Saining Xie. <a href="https://arxiv.org/abs/2212.09748"> Scalable Diffusion Models
              with Transformers</a>, arXiv preprint arXiv:2212.09748.</li><br>

        </ul>
      </div>

    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <code style="background-color:transparent;color:#EA48CA;">
        @article{dao2023lfm<br>
        &emsp;&emsp; author  = {Dao, Quan and Phung, Hao and Nguyen, Binh and Tran, Anh},<br>
        &emsp;&emsp; title   = {Flow Matching in Latent Space},<br>
        &emsp;&emsp; journal = {arXiv preprint arXiv:2307.08698},<br>
        &emsp;&emsp; year    = {2023},<br>
      }</code>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <!-- <div class="content has-text-centered">
        <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div> -->
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This page is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
